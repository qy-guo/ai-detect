{
  "best_global_step": 500,
  "best_metric": 0.8666081428527832,
  "best_model_checkpoint": "/storage/public/liutg/qyguo/qyguo_llm/LoRA/output/qlora/checkpoint-500",
  "epoch": 0.3711952487008166,
  "eval_steps": 100,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "entropy": 0.6895005851984024,
      "epoch": 0.014847809948032665,
      "grad_norm": 9.668927192687988,
      "learning_rate": 9.971789161098738e-06,
      "loss": 7.0013,
      "mean_token_accuracy": 0.2675123201683164,
      "num_tokens": 43580.0,
      "step": 20
    },
    {
      "entropy": 0.9768423341214657,
      "epoch": 0.02969561989606533,
      "grad_norm": 3.998697519302368,
      "learning_rate": 9.942093541202672e-06,
      "loss": 4.7233,
      "mean_token_accuracy": 0.36316491216421126,
      "num_tokens": 88611.0,
      "step": 40
    },
    {
      "entropy": 1.2297632992267609,
      "epoch": 0.044543429844097995,
      "grad_norm": 3.3590023517608643,
      "learning_rate": 9.912397921306609e-06,
      "loss": 3.5172,
      "mean_token_accuracy": 0.4374564096331596,
      "num_tokens": 131518.0,
      "step": 60
    },
    {
      "entropy": 1.5915580809116363,
      "epoch": 0.05939123979213066,
      "grad_norm": 1.8521921634674072,
      "learning_rate": 9.882702301410543e-06,
      "loss": 2.612,
      "mean_token_accuracy": 0.4959578923881054,
      "num_tokens": 176230.0,
      "step": 80
    },
    {
      "entropy": 1.7616040259599686,
      "epoch": 0.07423904974016332,
      "grad_norm": 1.7337368726730347,
      "learning_rate": 9.853006681514478e-06,
      "loss": 2.0404,
      "mean_token_accuracy": 0.5866400402039289,
      "num_tokens": 218506.0,
      "step": 100
    },
    {
      "epoch": 0.07423904974016332,
      "eval_entropy": 1.6152809533847154,
      "eval_loss": 1.7575441598892212,
      "eval_mean_token_accuracy": 0.6281301358042384,
      "eval_num_tokens": 218506.0,
      "eval_runtime": 180.9076,
      "eval_samples_per_second": 7.462,
      "eval_steps_per_second": 0.934,
      "step": 100
    },
    {
      "entropy": 1.425042960047722,
      "epoch": 0.08908685968819599,
      "grad_norm": 1.1179864406585693,
      "learning_rate": 9.823311061618413e-06,
      "loss": 1.5251,
      "mean_token_accuracy": 0.684717658162117,
      "num_tokens": 264296.0,
      "step": 120
    },
    {
      "entropy": 1.1821915745735168,
      "epoch": 0.10393466963622866,
      "grad_norm": 0.8406614065170288,
      "learning_rate": 9.793615441722347e-06,
      "loss": 1.261,
      "mean_token_accuracy": 0.7490689784288407,
      "num_tokens": 308216.0,
      "step": 140
    },
    {
      "entropy": 1.0783653430640698,
      "epoch": 0.11878247958426132,
      "grad_norm": 0.6564141511917114,
      "learning_rate": 9.76391982182628e-06,
      "loss": 1.1214,
      "mean_token_accuracy": 0.7730195052921772,
      "num_tokens": 352642.0,
      "step": 160
    },
    {
      "entropy": 1.044269186258316,
      "epoch": 0.133630289532294,
      "grad_norm": 0.6048628687858582,
      "learning_rate": 9.734224201930217e-06,
      "loss": 1.085,
      "mean_token_accuracy": 0.7797814778983593,
      "num_tokens": 397500.0,
      "step": 180
    },
    {
      "entropy": 1.0124592185020447,
      "epoch": 0.14847809948032664,
      "grad_norm": 0.7080657482147217,
      "learning_rate": 9.704528582034151e-06,
      "loss": 1.0401,
      "mean_token_accuracy": 0.7791872762143612,
      "num_tokens": 443657.0,
      "step": 200
    },
    {
      "epoch": 0.14847809948032664,
      "eval_entropy": 0.9905746279383553,
      "eval_loss": 0.9930102825164795,
      "eval_mean_token_accuracy": 0.7840167837735463,
      "eval_num_tokens": 443657.0,
      "eval_runtime": 180.4873,
      "eval_samples_per_second": 7.48,
      "eval_steps_per_second": 0.936,
      "step": 200
    },
    {
      "entropy": 0.9342116683721542,
      "epoch": 0.1633259094283593,
      "grad_norm": 0.5351558923721313,
      "learning_rate": 9.674832962138086e-06,
      "loss": 0.9427,
      "mean_token_accuracy": 0.7936213836073875,
      "num_tokens": 488034.0,
      "step": 220
    },
    {
      "entropy": 0.9212058506906032,
      "epoch": 0.17817371937639198,
      "grad_norm": 0.5063970685005188,
      "learning_rate": 9.64513734224202e-06,
      "loss": 0.9527,
      "mean_token_accuracy": 0.7941324502229691,
      "num_tokens": 532471.0,
      "step": 240
    },
    {
      "entropy": 0.916266492754221,
      "epoch": 0.19302152932442465,
      "grad_norm": 0.8036579489707947,
      "learning_rate": 9.615441722345955e-06,
      "loss": 0.9329,
      "mean_token_accuracy": 0.7950253330171109,
      "num_tokens": 577660.0,
      "step": 260
    },
    {
      "entropy": 0.8913437191396951,
      "epoch": 0.20786933927245732,
      "grad_norm": 1.0847864151000977,
      "learning_rate": 9.58574610244989e-06,
      "loss": 0.9354,
      "mean_token_accuracy": 0.7972764849662781,
      "num_tokens": 623604.0,
      "step": 280
    },
    {
      "entropy": 0.7963026609271765,
      "epoch": 0.22271714922049,
      "grad_norm": 0.7449643015861511,
      "learning_rate": 9.556050482553823e-06,
      "loss": 0.8309,
      "mean_token_accuracy": 0.81220748052001,
      "num_tokens": 667769.0,
      "step": 300
    },
    {
      "epoch": 0.22271714922049,
      "eval_entropy": 0.8556806663789692,
      "eval_loss": 0.8875965476036072,
      "eval_mean_token_accuracy": 0.8000607423528412,
      "eval_num_tokens": 667769.0,
      "eval_runtime": 180.4739,
      "eval_samples_per_second": 7.48,
      "eval_steps_per_second": 0.936,
      "step": 300
    },
    {
      "entropy": 0.7592702686786652,
      "epoch": 0.23756495916852263,
      "grad_norm": 0.7062492966651917,
      "learning_rate": 9.526354862657759e-06,
      "loss": 0.7897,
      "mean_token_accuracy": 0.8179524511098861,
      "num_tokens": 711229.0,
      "step": 320
    },
    {
      "entropy": 0.7949169602245092,
      "epoch": 0.2524127691165553,
      "grad_norm": 0.5233269333839417,
      "learning_rate": 9.496659242761694e-06,
      "loss": 0.8578,
      "mean_token_accuracy": 0.8080503150820733,
      "num_tokens": 755379.0,
      "step": 340
    },
    {
      "entropy": 0.8105335552245378,
      "epoch": 0.267260579064588,
      "grad_norm": 0.5730036497116089,
      "learning_rate": 9.466963622865628e-06,
      "loss": 0.8673,
      "mean_token_accuracy": 0.8067128673195839,
      "num_tokens": 800465.0,
      "step": 360
    },
    {
      "entropy": 0.8111094236373901,
      "epoch": 0.28210838901262064,
      "grad_norm": 0.8131565451622009,
      "learning_rate": 9.437268002969563e-06,
      "loss": 0.8607,
      "mean_token_accuracy": 0.808198244869709,
      "num_tokens": 844683.0,
      "step": 380
    },
    {
      "entropy": 0.7683810755610466,
      "epoch": 0.2969561989606533,
      "grad_norm": 0.4769507348537445,
      "learning_rate": 9.407572383073498e-06,
      "loss": 0.8141,
      "mean_token_accuracy": 0.8176673278212547,
      "num_tokens": 888540.0,
      "step": 400
    },
    {
      "epoch": 0.2969561989606533,
      "eval_entropy": 0.8288109739856607,
      "eval_loss": 0.8734232187271118,
      "eval_mean_token_accuracy": 0.8021065455216628,
      "eval_num_tokens": 888540.0,
      "eval_runtime": 180.3891,
      "eval_samples_per_second": 7.484,
      "eval_steps_per_second": 0.937,
      "step": 400
    },
    {
      "entropy": 0.8255525082349777,
      "epoch": 0.311804008908686,
      "grad_norm": 0.8438613414764404,
      "learning_rate": 9.377876763177432e-06,
      "loss": 0.8771,
      "mean_token_accuracy": 0.8015494227409363,
      "num_tokens": 932915.0,
      "step": 420
    },
    {
      "entropy": 0.8262103144079447,
      "epoch": 0.3266518188567186,
      "grad_norm": 0.5607431530952454,
      "learning_rate": 9.348181143281367e-06,
      "loss": 0.871,
      "mean_token_accuracy": 0.8063470378518105,
      "num_tokens": 977568.0,
      "step": 440
    },
    {
      "entropy": 0.8002087343484163,
      "epoch": 0.3414996288047513,
      "grad_norm": 0.6004900336265564,
      "learning_rate": 9.318485523385302e-06,
      "loss": 0.8542,
      "mean_token_accuracy": 0.812156880646944,
      "num_tokens": 1021210.0,
      "step": 460
    },
    {
      "entropy": 0.922423979640007,
      "epoch": 0.35634743875278396,
      "grad_norm": 0.489417165517807,
      "learning_rate": 9.288789903489236e-06,
      "loss": 0.9841,
      "mean_token_accuracy": 0.7854196295142174,
      "num_tokens": 1067988.0,
      "step": 480
    },
    {
      "entropy": 0.8567861076444387,
      "epoch": 0.3711952487008166,
      "grad_norm": 0.9245506525039673,
      "learning_rate": 9.259094283593171e-06,
      "loss": 0.9064,
      "mean_token_accuracy": 0.8005307108163834,
      "num_tokens": 1112657.0,
      "step": 500
    },
    {
      "epoch": 0.3711952487008166,
      "eval_entropy": 0.8384731612967317,
      "eval_loss": 0.8666081428527832,
      "eval_mean_token_accuracy": 0.8019767407129502,
      "eval_num_tokens": 1112657.0,
      "eval_runtime": 180.6428,
      "eval_samples_per_second": 7.473,
      "eval_steps_per_second": 0.936,
      "step": 500
    }
  ],
  "logging_steps": 20,
  "max_steps": 6735,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 100,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.330793337798656e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
