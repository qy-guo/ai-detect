{
  "best_global_step": 200,
  "best_metric": 0.9351773858070374,
  "best_model_checkpoint": "/storage/public/liutg/qyguo/qyguo_llm/LoRA/output/lora_4/checkpoint-200",
  "epoch": 0.14847809948032664,
  "eval_steps": 100,
  "global_step": 200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "entropy": 0.6792499400675297,
      "epoch": 0.014847809948032665,
      "grad_norm": 12.305797576904297,
      "learning_rate": 9.971789161098738e-06,
      "loss": 7.0113,
      "mean_token_accuracy": 0.2703643975779414,
      "num_tokens": 43580.0,
      "step": 20
    },
    {
      "entropy": 0.9233526706695556,
      "epoch": 0.02969561989606533,
      "grad_norm": 4.116633415222168,
      "learning_rate": 9.942093541202672e-06,
      "loss": 4.9189,
      "mean_token_accuracy": 0.3720073260366917,
      "num_tokens": 88611.0,
      "step": 40
    },
    {
      "entropy": 1.189786460250616,
      "epoch": 0.044543429844097995,
      "grad_norm": 3.1892340183258057,
      "learning_rate": 9.912397921306609e-06,
      "loss": 3.5829,
      "mean_token_accuracy": 0.4424947012215853,
      "num_tokens": 131518.0,
      "step": 60
    },
    {
      "entropy": 1.4724523946642876,
      "epoch": 0.05939123979213066,
      "grad_norm": 1.9622673988342285,
      "learning_rate": 9.882702301410543e-06,
      "loss": 2.6549,
      "mean_token_accuracy": 0.5012056291103363,
      "num_tokens": 176230.0,
      "step": 80
    },
    {
      "entropy": 1.6653242886066437,
      "epoch": 0.07423904974016332,
      "grad_norm": 1.675202488899231,
      "learning_rate": 9.853006681514478e-06,
      "loss": 1.994,
      "mean_token_accuracy": 0.5834414180368185,
      "num_tokens": 218506.0,
      "step": 100
    },
    {
      "epoch": 0.07423904974016332,
      "eval_entropy": 1.5424304474034958,
      "eval_loss": 1.693054437637329,
      "eval_mean_token_accuracy": 0.6286287378277299,
      "eval_num_tokens": 218506.0,
      "eval_runtime": 166.4977,
      "eval_samples_per_second": 8.108,
      "eval_steps_per_second": 1.015,
      "step": 100
    },
    {
      "entropy": 1.3425858721137047,
      "epoch": 0.08908685968819599,
      "grad_norm": 0.9984298944473267,
      "learning_rate": 9.823311061618413e-06,
      "loss": 1.4546,
      "mean_token_accuracy": 0.6988577149808407,
      "num_tokens": 264296.0,
      "step": 120
    },
    {
      "entropy": 1.1070168145000934,
      "epoch": 0.10393466963622866,
      "grad_norm": 1.008787989616394,
      "learning_rate": 9.793615441722347e-06,
      "loss": 1.2294,
      "mean_token_accuracy": 0.7522017173469067,
      "num_tokens": 308216.0,
      "step": 140
    },
    {
      "entropy": 1.0353194661438465,
      "epoch": 0.11878247958426132,
      "grad_norm": 0.9549691081047058,
      "learning_rate": 9.76391982182628e-06,
      "loss": 1.0982,
      "mean_token_accuracy": 0.7715935938060283,
      "num_tokens": 352642.0,
      "step": 160
    },
    {
      "entropy": 1.0186566516757012,
      "epoch": 0.133630289532294,
      "grad_norm": 0.8368224501609802,
      "learning_rate": 9.734224201930217e-06,
      "loss": 1.0465,
      "mean_token_accuracy": 0.7812905199825764,
      "num_tokens": 397500.0,
      "step": 180
    },
    {
      "entropy": 0.9904132351279259,
      "epoch": 0.14847809948032664,
      "grad_norm": 0.6374759078025818,
      "learning_rate": 9.704528582034151e-06,
      "loss": 0.9888,
      "mean_token_accuracy": 0.783664857596159,
      "num_tokens": 443657.0,
      "step": 200
    },
    {
      "epoch": 0.14847809948032664,
      "eval_entropy": 0.9455072336648342,
      "eval_loss": 0.9351773858070374,
      "eval_mean_token_accuracy": 0.7917197731119641,
      "eval_num_tokens": 443657.0,
      "eval_runtime": 166.1601,
      "eval_samples_per_second": 8.125,
      "eval_steps_per_second": 1.017,
      "step": 200
    }
  ],
  "logging_steps": 20,
  "max_steps": 6735,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 100,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 5,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.122997173906637e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
